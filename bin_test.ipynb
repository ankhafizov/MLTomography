{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import jaccard_score\n",
    "\n",
    "from skimage import filters\n",
    "\n",
    "import generator\n",
    "import data_manager as dm\n",
    "import pixel_counter as pc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preview_phantoms(phantom, processed_phantom, title):\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(20, 10))\n",
    "    fig.suptitle(title)\n",
    "    if len(phantom.shape) == 3:\n",
    "        axes[0].imshow(phantom[:, :, 0], cmap='gray')\n",
    "        axes[1].imshow(processed_phantom[:, :, 0], cmap='gray')\n",
    "    else:\n",
    "        axes[0].imshow(phantom, cmap='gray')\n",
    "        axes[1].imshow(processed_phantom, cmap='gray')\n",
    "\n",
    "\n",
    "def show_phantoms_stats(phantom, processed_phantom, title):\n",
    "    porous = (phantom == 1).sum()\n",
    "    stones = (phantom == 0).sum()\n",
    "    print(f'porosity: { porous / (porous + stones) }\\n')\n",
    "    ph = np.ravel(phantom)\n",
    "    p_ph = np.ravel(processed_phantom)\n",
    "    p_ph_porous = p_ph[ph == 1]\n",
    "    p_ph_stones = p_ph[ph == 0]\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    plt.title(title)\n",
    "    plt.hist(p_ph, 255, [0, 1], color='lightgray')\n",
    "    plt.hist(p_ph_porous, 255, [0, 1], histtype='step', color='red')\n",
    "    plt.hist(p_ph_stones, 255, [0, 1], histtype='step', color='blue')\n",
    "\n",
    "\n",
    "def generate_phantoms(preview=False):\n",
    "\n",
    "    for p in porosity:\n",
    "        for b in blobiness:\n",
    "            for n in noise:\n",
    "                phantom, processed_phantom = generator.create_phantom_and_process(\n",
    "                    shape, p, b, n, num_of_angles, tag, preview=preview, noise_method=noise_method\n",
    "                )\n",
    "                title = f'porosity: { p }, blobiness: { b }, noise: { n }'\n",
    "                preview_phantoms(phantom, processed_phantom, title)\n",
    "                show_phantoms_stats(phantom, processed_phantom, title)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 100\n",
    "dim = 3\n",
    "shape = tuple(size for _ in range(dim))\n",
    "porosity = np.array([0.5])\n",
    "blobiness = np.array([1])\n",
    "noise_method = 'poisson'\n",
    "noise = np.array([1e3])\n",
    "num_of_angles = 90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag = 'train'\n",
    "generate_phantoms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_info = dm.show_data_info()\n",
    "data_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_lenght = np.prod(shape)\n",
    "coeff = 100\n",
    "sample_lenght = (im_lenght/coeff).astype(np.int)\n",
    "indices = (np.random.rand(sample_lenght) * im_lenght).astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_value_from_data_info(key, data_info, index):\n",
    "    return data_info[key][index[0]]\n",
    "    \n",
    "    \n",
    "def get_params_from_data_info(data_info, index):\n",
    "\n",
    "    porosity = get_value_from_data_info('porosity', data_info, index)\n",
    "    blobiness = get_value_from_data_info('blobiness', data_info, index)\n",
    "    noise = get_value_from_data_info('noise', data_info, index)\n",
    "\n",
    "    return porosity, blobiness, noise\n",
    "\n",
    "\n",
    "def scatter_plot(x, y, colors, title):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.xlim(0, 1)\n",
    "    plt.ylim(0, 1)\n",
    "    plt.scatter(x, y, marker='.', c=colors)\n",
    "    plt.title(title)\n",
    "\n",
    "\n",
    "def scatter_plot_values(x, y, origin, title):\n",
    "    x_part = np.take(x, indices)\n",
    "    y_part = np.take(y, indices)\n",
    "    origin_part = np.take(origin, indices)\n",
    "    colors = ['red' if el else 'blue' for el in origin_part]\n",
    "    scatter_plot(x_part, y_part, colors, title)\n",
    "\n",
    "\n",
    "def otsu_bin(image):\n",
    "    threshold = filters.threshold_otsu(image)\n",
    "    return image > threshold, threshold\n",
    "\n",
    "\n",
    "def li_bin(image):\n",
    "    threshold = filters.threshold_li(image)\n",
    "    return image > threshold, threshold\n",
    "\n",
    "\n",
    "def local_bin(image):\n",
    "    \n",
    "    def l_b(im):\n",
    "        return im > filters.threshold_local(im, 15)\n",
    "    \n",
    "    if len(image.shape) == 2:\n",
    "        return l_b(image)\n",
    "    elif len(image.shape) == 3:\n",
    "        return np.asarray([l_b(image[i, :, :]) for i in range(image.shape[0])])\n",
    "    else:\n",
    "        raise ValueError('incorrect image shape')\n",
    "\n",
    "\n",
    "def niblack_bin(image):\n",
    "    return image > filters.threshold_niblack(image, 3)\n",
    "\n",
    "\n",
    "def binarize_image(image, orig_image, pp, npa):\n",
    "\n",
    "    title = 'otsu binarization'\n",
    "    otsu_bin_image, otsu_threshold = otsu_bin(image)\n",
    "    scatter_plot_values(pp, npa, otsu_bin_image.flatten(), title)\n",
    "    preview_phantoms(otsu_bin_image, orig_image, title)\n",
    "    print(f'{ title } jaccard score: { jaccard_score(otsu_bin_image.flatten(), orig_image.flatten()) }')\n",
    "    \n",
    "    title = 'li binarization'\n",
    "    li_bin_image, li_threshold = li_bin(image)\n",
    "    scatter_plot_values(pp, npa, li_bin_image.flatten(), title)\n",
    "    preview_phantoms(li_bin_image, orig_image, title)\n",
    "    print(f'{ title } jaccard score: { jaccard_score(li_bin_image.flatten(), orig_image.flatten()) }')\n",
    "\n",
    "    title = 'local binarization'\n",
    "    local_bin_image = local_bin(image)\n",
    "    scatter_plot_values(pp, npa, local_bin_image.flatten(), title)\n",
    "#     preview_phantoms(local_bin_image, orig_image, title)\n",
    "    print(f'{ title } jaccard score: { jaccard_score(local_bin_image.flatten(), orig_image.flatten()) }')\n",
    "\n",
    "    title = 'niblack binarization'\n",
    "    niblack_bin_image = niblack_bin(image)\n",
    "    scatter_plot_values(pp, npa, niblack_bin_image.flatten(), title)\n",
    "#     preview_phantoms(niblack_bin_image, orig_image, title)\n",
    "    print(f'{ title } jaccard score: { jaccard_score(niblack_bin_image.flatten(), orig_image.flatten()) }')\n",
    "\n",
    "\n",
    "def count_npa_vs_pp(images_tag):\n",
    "\n",
    "    df = data_info[data_info['tag'] == images_tag]\n",
    "\n",
    "    for index, data_id in np.ndenumerate(df['id_indx']):\n",
    "        \n",
    "        porosity, blobiness, noise = get_params_from_data_info(data_info, index)\n",
    "        title = f'porosity { porosity }, blobiness { blobiness }, noise { noise }'\n",
    "\n",
    "        # pp — proc_phantom\n",
    "        # npa — neighbor_pixel_average\n",
    "        # op — orig_phantom\n",
    "\n",
    "        pp, npa, op, proc_phantom, orig_phantom = pc.count_neighbor_average_array_and_save(dim, data_id, images_tag)\n",
    "        scatter_plot_values(pp, npa, op, title)\n",
    "        binarize_image(proc_phantom, orig_phantom, pp, npa)\n",
    "\n",
    "\n",
    "count_npa_vs_pp(tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag = 'test'\n",
    "generate_phantoms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_info = dm.show_data_info()\n",
    "data_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_npa_vs_pp(tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data_info.query('tag == \"train\"')\n",
    "test_data = data_info.query('tag == \"test\"')\n",
    "\n",
    "\n",
    "def train_and_test():\n",
    "    \n",
    "    for index, data_id in np.ndenumerate(train_data['id_indx']):\n",
    "        \n",
    "        train_datum = train_data.query(f'id_indx == \"{ data_id }\"')\n",
    "        test_datum = test_data.query(f'id_indx == \"{ data_id }\"')\n",
    "\n",
    "        if train_datum.empty or test_datum.empty:\n",
    "            print(f'can\\'t train&test model at index { data_id }' )\n",
    "            continue\n",
    "        \n",
    "        porosity, blobiness, noise = get_params_from_data_info(train_data, index)\n",
    "        title = f'porosity { porosity }, blobiness { blobiness }, noise { noise }'\n",
    "        \n",
    "        train_pixels_df = dm.get_data(dimension=dim, id_indx=data_id, what_to_return='csv', tag='train')\n",
    "        X_train = np.asarray(train_pixels_df[['neighbor_average', 'proc_phantom_pixel_values']])\n",
    "        Y_train = np.asarray(train_pixels_df['pixel_real_value'])\n",
    "        train_scaler = preprocessing.StandardScaler()\n",
    "        train_scaler.fit(X_train)\n",
    "        train_scaler.transform(X_train)\n",
    "        LR = LogisticRegression(C=1, solver='liblinear').fit(X_train, Y_train)\n",
    "        \n",
    "        print(f'train: { title }')\n",
    "        print(f'mean: { train_scaler.mean_ }, var: { train_scaler.var_ }, samples_seen: { train_scaler.n_samples_seen_ }')\n",
    "        \n",
    "        print('test:')\n",
    "        pp, npa, op, proc_phantom, orig_phantom = pc.count_neighbor_average_array_and_save(dim, data_id, 'test')\n",
    "        scatter_plot_values(pp, npa, op, title)\n",
    "        \n",
    "        test_pixels_df = dm.get_data(dimension=dim, id_indx=data_id, what_to_return='csv', tag='test')\n",
    "        X_test = np.asarray(test_pixels_df[['neighbor_average', 'proc_phantom_pixel_values']])\n",
    "        Y_test = np.asarray(test_pixels_df['pixel_real_value'])\n",
    "        test_scaler = preprocessing.StandardScaler()\n",
    "        test_scaler.fit(X_train)\n",
    "        test_scaler.transform(X_train)\n",
    "\n",
    "        print(f'mean: { test_scaler.mean_ }, var: { test_scaler.var_ }, samples_seen: { test_scaler.n_samples_seen_ }')\n",
    "        \n",
    "        Y_predict = LR.predict(X_test)\n",
    "        print(LR.coef_, LR.intercept_, LR.classes_)\n",
    "        print(f'prediction score: { LR.score(X_test, Y_test) }')\n",
    "        print(f'jaccard score: { jaccard_score(Y_predict, Y_test) }')\n",
    "        print(f'\\n')\n",
    "        \n",
    "        coef = LR.coef_\n",
    "        intercept = LR.intercept_\n",
    "        x = X_test[:, 1]\n",
    "        y = X_test[:, 0]\n",
    "\n",
    "        def line(x0):\n",
    "            return (-(x0 * coef[0, 1]) - intercept[0]) / coef[0, 0]\n",
    "\n",
    "        xmin, xmax = x.min(), x.max()\n",
    "        \n",
    "        scatter_plot_values(x, y, Y_test, title)\n",
    "        plt.plot([xmin, xmax], [line(xmin), line(xmax)], color='gray')\n",
    "\n",
    "        scatter_plot_values(x, y, Y_predict, title)\n",
    "        \n",
    "        predict_image = np.reshape(Y_predict, shape)\n",
    "        preview_phantoms(predict_image, orig_phantom, f'predicted vs origin { title }')\n",
    "\n",
    "\n",
    "train_and_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
